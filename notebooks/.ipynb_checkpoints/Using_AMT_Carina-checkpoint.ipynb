{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661713de-39d0-4029-affc-56ce3af2ceb9",
   "metadata": {},
   "source": [
    "# Generating with PreTrained AMT Version\n",
    "\n",
    "In this notebook, I will will be writing code to pull the AMT from Hugging Face then using it here\n",
    "\n",
    "### Links : \n",
    "- https://huggingface.co/docs/transformers/en/quicktour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c515bc1d-1429-413e-a08a-47a168a591e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Exploration_Aquila.ipynb  Using_AMT_Carina.ipynb  tmp.mid\n",
      "Lakh_Statistics_Bootes.ipynb   \u001b[0m\u001b[01;34manticipation\u001b[0m/           transfomers.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da375eff-4249-4a84-b170-3cba9c6c6302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr4/cs640/rakin374/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at stanford-crfm/music-small-ar-inter-100k were not used when initializing GPT2Model: ['token_out_embeddings']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2Model were not initialized from the model checkpoint at stanford-crfm/music-small-ar-inter-100k and are newly initialized: ['h.3.attn.bias', 'h.11.attn.bias', 'h.9.attn.bias', 'h.1.attn.bias', 'h.4.attn.bias', 'h.0.attn.bias', 'h.6.attn.bias', 'h.2.attn.bias', 'h.10.attn.bias', 'h.7.attn.bias', 'h.5.attn.bias', 'h.8.attn.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"stanford-crfm/music-small-ar-inter-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96ceb2-86cd-48e5-9168-fb8842926559",
   "metadata": {},
   "source": [
    "## Code From Thickstun\n",
    "- https://colab.research.google.com/drive/1HCQDtGFwROpHRqcmZbV0byqbxDb74YGu?usp=sharing#scrollTo=PlMSkS-1qJyj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693cb172-d26a-48b3-9d60-81be280dbcea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'anticipation'...\n",
      "remote: Enumerating objects: 1343, done.\u001b[K\n",
      "remote: Counting objects: 100% (757/757), done.\u001b[K\n",
      "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
      "remote: Total 1343 (delta 575), reused 714 (delta 548), pack-reused 586 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1343/1343), 56.04 MiB | 25.40 MiB/s, done.\n",
      "Resolving deltas: 100% (898/898), done.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing ./anticipation\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: anticipation\n",
      "  Building wheel for anticipation (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for anticipation: filename=anticipation-1.0-py3-none-any.whl size=18680 sha256=4544b5065f0169fbd90e045dfc29e8379999860cc0bdef17d6fbe13618d5f87a\n",
      "  Stored in directory: /scratch/1139174.1.academic-gpu/pip-ephem-wheel-cache-ufdu3ok8/wheels/dd/41/11/84cee4b6b78c0052553fe37cf06402e29a87c692fb302c3cf3\n",
      "Successfully built anticipation\n",
      "Installing collected packages: anticipation\n",
      "Successfully installed anticipation-1.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib==3.7.1 (from -r anticipation/requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting midi2audio==0.1.1 (from -r anticipation/requirements.txt (line 2))\n",
      "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting mido==1.2.10 (from -r anticipation/requirements.txt (line 3))\n",
      "  Downloading mido-1.2.10-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from -r anticipation/requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: torch>=2.0.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from -r anticipation/requirements.txt (line 5)) (2.4.0)\n",
      "Collecting transformers==4.29.2 (from -r anticipation/requirements.txt (line 6))\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.65.0 (from -r anticipation/requirements.txt (line 7))\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m325.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: filelock in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (0.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2024.7.24)\n",
      "Requirement already satisfied: requests in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2.32.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->-r anticipation/requirements.txt (line 6))\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (1.13.0)\n",
      "Requirement already satisfied: networkx in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (2024.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from jinja2->torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages (from sympy->torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (1.3.0)\n",
      "Downloading matplotlib-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m338.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m233.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m345.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m225.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, mido, midi2audio, tqdm, matplotlib, transformers\n",
      "\u001b[33m  WARNING: The scripts midi2audio and midiplay are installed in '/usr4/cs640/rakin374/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tqdm is installed in '/usr4/cs640/rakin374/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/usr4/cs640/rakin374/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.20.0 requires tqdm>=4.66.3, but you have tqdm 4.65.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-3.7.1 midi2audio-0.1.1 mido-1.2.10 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.29.2\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/jthickstun/anticipation.git\n",
    "# !pip install ./anticipation\n",
    "# !pip install -r anticipation/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d92243-d839-42d5-b63c-85748ad5f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,time\n",
    "\n",
    "import midi2audio\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from anticipation import ops\n",
    "from anticipation.sample import generate\n",
    "from anticipation.tokenize import extract_instruments\n",
    "from anticipation.convert import events_to_midi,midi_to_events\n",
    "from anticipation.visuals import visualize\n",
    "from anticipation.config import *\n",
    "from anticipation.vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02fbb931-0acf-48fc-af9c-bfcff32a9f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<midi2audio.FluidSynth object at 0x14e21942e390>\n"
     ]
    }
   ],
   "source": [
    "SMALL_MODEL = 'stanford-crfm/music-small-800k'     # faster inference, worse sample quality\n",
    "MEDIUM_MODEL = 'stanford-crfm/music-medium-800k'   # slower inference, better sample quality\n",
    "LARGE_MODEL = 'stanford-crfm/music-large-800k'     # slowest inference, best sample quality\n",
    "\n",
    "# load an anticipatory music transformer\n",
    "model = AutoModelForCausalLM.from_pretrained(SMALL_MODEL).cuda()\n",
    "\n",
    "os.environ['FLUIDSYNTH_PATH'] = '/projectnb/cs505aw/projects/bb/fluidsynth'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/projectnb/cs505aw/projects/bb/fluidsynth/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "\n",
    "# a MIDI synthesizer\n",
    "fs = midi2audio.FluidSynth('/projectnb/cs505aw/projects/bb/FluidR3_GM.sf2')\n",
    "\n",
    "# the MIDI synthesis script\n",
    "def synthesize(fs, tokens):\n",
    "    mid = events_to_midi(tokens)\n",
    "    mid.save('tmp.mid')\n",
    "    fs.midi_to_audio('tmp.mid', 'tmp.wav')\n",
    "    return 'tmp.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3de4b1-8b8d-4d71-aa0b-c76dd891a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr4/cs640/rakin374/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at stanford-crfm/music-small-800k were not used when initializing GPT2LMHeadModel: ['token_out_embeddings']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SoundFont from: /projectnb/cs505aw/projects/bb/FluidR3_GM.sf2\n",
      "FluidSynth successfully initialized.\n",
      "MIDI file saved as 'tmp.mid'\n",
      "FluidSynth runtime version 2.4.0\n",
      "Copyright (C) 2000-2024 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "Rendering audio to file 'tmp.wav'..\n",
      "Audio file saved as 'tmp.wav'\n",
      "Error during synthesis: File format b'\\x00\\x00\\x00\\x00' not understood. Only 'RIFF', 'RIFX', and 'RF64' supported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import midi2audio\n",
    "from transformers import AutoModelForCausalLM\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Set FluidSynth environment if needed (example)\n",
    "os.environ['FLUIDSYNTH_PATH'] = '/projectnb/cs505aw/projects/bb/fluidsynth'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/projectnb/cs505aw/projects/bb/fluidsynth/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "\n",
    "# Check model\n",
    "SMALL_MODEL = 'stanford-crfm/music-small-800k'\n",
    "model = AutoModelForCausalLM.from_pretrained(SMALL_MODEL).cuda()\n",
    "\n",
    "# MIDI synthesizer setup\n",
    "soundfont_path = '/projectnb/cs505aw/projects/bb/FluidR3_GM.sf2'\n",
    "print(f\"Loading SoundFont from: {soundfont_path}\")\n",
    "\n",
    "try:\n",
    "    fs = midi2audio.FluidSynth(soundfont_path)\n",
    "    print(\"FluidSynth successfully initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing FluidSynth: {e}\")\n",
    "\n",
    "# MIDI synthesis script\n",
    "def synthesize(fs, tokens):\n",
    "    try:\n",
    "        mid = events_to_midi(tokens)  # Ensure this function creates a valid MIDI\n",
    "        mid.save('tmp.mid')\n",
    "        print(\"MIDI file saved as 'tmp.mid'\")\n",
    "        \n",
    "        # Convert MIDI to WAV using FluidSynth\n",
    "        fs.midi_to_audio('tmp.mid', 'tmp.wav')\n",
    "        print(\"Audio file saved as 'tmp.wav'\")\n",
    "        \n",
    "        # Load the WAV file into a NumPy array\n",
    "        rate, data = wavfile.read('tmp.wav')\n",
    "        print(f\"Loaded audio data with shape: {data.shape}, rate: {rate}\")\n",
    "\n",
    "        # Return the audio data to be used with the Audio class\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error during synthesis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Assuming you are calling the synthesize function with `fs` and `tokens`\n",
    "audio_data = synthesize(fs, unconditional_tokens)  # `unconditional_tokens` should be defined\n",
    "if audio_data is not None:\n",
    "    Audio(audio_data, rate=44100)  # Play the audio with the correct sample rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c9275a-6acd-4a9e-89a9-45e302a1a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 989/1000 [00:03<00:00, 259.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved as 'tmp.mid'\n",
      "FluidSynth runtime version 2.4.0\n",
      "Copyright (C) 2000-2024 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "Rendering audio to file 'tmp.wav'..\n",
      "Audio file saved as 'tmp.wav'\n",
      "Error during synthesis: File format b'\\x00\\x00\\x00\\x00' not understood. Only 'RIFF', 'RIFX', and 'RF64' supported.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No audio data found. Expecting filename, url, or data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/projectnb/cs505aw/projects/bb/fluidsynth/bin:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m unconditional_tokens \u001b[38;5;241m=\u001b[39m generate(model, start_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end_time\u001b[38;5;241m=\u001b[39mlength, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.98\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munconditional_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m44100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/academic-ml/fall-2024/install/fall-2024-pyt/lib/python3.11/site-packages/IPython/lib/display.py:115\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, autoplay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    113\u001b[0m              element_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo audio data found. Expecting filename, url, or data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo url found. Expecting url when embed=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No audio data found. Expecting filename, url, or data."
     ]
    }
   ],
   "source": [
    "import os\n",
    "length = 10\n",
    "os.environ['PATH'] = '/projectnb/cs505aw/projects/bb/fluidsynth/bin:' + os.environ['PATH']\n",
    "unconditional_tokens = generate(model, start_time=0, end_time=length, top_p=.98)\n",
    "Audio(synthesize(fs, unconditional_tokens), rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8512f2a-1fcb-4c58-a02c-4f41f6c1b2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487651b1-b34d-464e-8a12-b874207f2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratch Space Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f228658-f494-4f09-a865-b3a0f76f9a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mpapers\u001b[0m/  \u001b[01;34mpond\u001b[0m/  \u001b[01;34mpresentations\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8509ef2c-e64d-4340-ac0e-6f86d4e62d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fluidsynth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfluidsynth\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fluidsynth' is not defined"
     ]
    }
   ],
   "source": [
    "fluidsynth --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edbe7cda-c00a-4b75-b5ce-ec9b6b4676d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mpapers\u001b[0m/  \u001b[01;34mpond\u001b[0m/  \u001b[01;34mpresentations\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053083f6-6880-4784-8b75-8ef9323be6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
